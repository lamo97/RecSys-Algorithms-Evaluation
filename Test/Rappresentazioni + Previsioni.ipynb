{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86dfde6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\glamo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# correzione dell'ordine di stampa\n",
    "import functools\n",
    "from operator import rshift\n",
    "print = functools.partial(print, flush=True)\n",
    "\n",
    "# import dei moduli per Content Analyzer, Recommender System e Evaluation come librerie\n",
    "from clayrs import content_analyzer as ca\n",
    "from clayrs import recsys as rs\n",
    "from clayrs import evaluation as eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d45c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path del dataset\n",
    "path = 'C:/Users/glamo/Desktop/Repository/RecSys-Algorithms-Evaluation/Dataset/Movielens 100k/'\n",
    "\n",
    "# apertura del file contenente i film\n",
    "items = open(path + 'items_info.json')\n",
    "\n",
    "# apertura del file con i ratings\n",
    "ratings = open(path + 'ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d87f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurazione del content analyzer\n",
    "ca_config = ca.ItemAnalyzerConfig(\n",
    "    source = ca.JSONFile(path + 'items_info.json'),\n",
    "    id = 'movielens_id',\n",
    "    output_directory = path + 'movies_codified/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73d9ea4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\glamo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\glamo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\glamo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\glamo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\glamo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\glamo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# inserimento delle rappresentazioni multiple\n",
    "ca_config.add_multiple_config(\n",
    "    'plot',\n",
    "    [\n",
    "        ca.FieldConfig(ca.SkLearnTfIdf(),\n",
    "                       preprocessing=ca.NLTK(stopwords_removal=True, lemmatization=True),\n",
    "                       id='tfidf'),\n",
    "    \n",
    "        ca.FieldConfig(ca.Word2DocEmbedding(ca.Gensim('glove-twitter-50'), combining_technique=ca.Centroid()),\n",
    "                       ca.NLTK(stopwords_removal=True, lemmatization=True),\n",
    "                       id='gensim')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35fb73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - ***********   Processing field: plot   *********** (content_analyzer_main.py:188)\n",
      "\u001b[39mINFO\u001b[0m - Computing tf-idf with SkLearnTfIdf (tf_idf.py:92)\n",
      "\u001b[39mINFO\u001b[0m - Downloading/Loading Gensim glove-twitter-50 (gensim.py:31)\n",
      "Processing and producing contents with Gensim glove-twitter-50:  100%|████████████████████████| 1682/1682 [00:20<00:00]\n",
      "Serializing contents:  100%|██████████████████████████████████████████████████████████████████| 1682/1682 [00:08<00:00]\n"
     ]
    }
   ],
   "source": [
    "# serializzazione degli item\n",
    "ca.ContentAnalyzer(config = ca_config).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "188a8aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing ratings:  100%|█████████████████████████████████████████████████████████████████| 100000/100000 [00:00<00:00]\n"
     ]
    }
   ],
   "source": [
    "# Recommender: Centroid Vector Algorithm\n",
    "ratings = ca.Ratings(ca.CSVFile(path + 'ratings.csv'))\n",
    "\n",
    "centroid_vector = rs.CentroidVector({'plot': 'tfidf'},\n",
    "                                    similarity = rs.CosineSimilarity())                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a843289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing KFoldPartitioningTechnique:  100%|███████████████████████████████████████████████████| 943/943 [00:00<00:00]\n",
      "\u001b[39mINFO\u001b[0m - Don't worry if it looks stuck at first (recsys.py:349)\n",
      "\u001b[39mINFO\u001b[0m - First iterations will stabilize the estimated remaining time (recsys.py:350)\n",
      "Computing fit_rank for user 1:  100%|███████████████████████████████████████████████████████████████| 3/3 [00:00<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_id item_id     score\n",
      "0       2     297  0.240214\n",
      "1       2     316  0.070412\n",
      "2       2     291  0.056568\n",
      "3       8      50  0.126758\n",
      "4       8     511  0.100450\n",
      "5       8     385  0.093093\n",
      "6       1      45  0.129885\n",
      "7       1      65  0.115058\n",
      "8       1     103  0.113256\n"
     ]
    }
   ],
   "source": [
    "# Split Test Set e Training Set\n",
    "train_list, test_list = rs.KFoldPartitioning(n_splits=2).split_all(ratings)\n",
    "                        #s.KFoldPartitioning(n_splits=2).split_all(ratings)\n",
    "\n",
    "first_training_set = train_list[0]\n",
    "\n",
    "cbrs = rs.ContentBasedRS(centroid_vector, \n",
    "                         first_training_set, \n",
    "                         (path + '/movies_codified'))\n",
    "\n",
    "first_test_set = test_list[0]\n",
    "\n",
    "rank = cbrs.fit_rank(first_test_set, \n",
    "                     user_id_list = ['8', '2', '1'],\n",
    "                     n_recs = 3)\n",
    "\n",
    "print(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c16292b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Don't worry if it looks stuck at first (recsys.py:349)\n",
      "\u001b[39mINFO\u001b[0m - First iterations will stabilize the estimated remaining time (recsys.py:350)\n",
      "Computing fit_rank for user 774:  100%|█████████████████████████████████████████████████████████| 943/943 [00:17<00:00]\n",
      "\u001b[39mINFO\u001b[0m - Don't worry if it looks stuck at first (recsys.py:349)\n",
      "\u001b[39mINFO\u001b[0m - First iterations will stabilize the estimated remaining time (recsys.py:350)\n",
      "Computing fit_rank for user 774:  100%|█████████████████████████████████████████████████████████| 943/943 [00:18<00:00]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "for train_set, test_set in zip(train_list, test_list):\n",
    "    cbrs = rs.ContentBasedRS(centroid_vector, train_set, (path + '/movies_codified'))\n",
    "    rank_to_append = cbrs.fit_rank(test_set)\n",
    "    result_list.append(rank_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4349d78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d9343c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

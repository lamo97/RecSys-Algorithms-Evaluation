{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75505d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import dataframe_image as dfi\n",
    "\n",
    "def getFileInfo(filename):\n",
    "    file_info = {'fields' : '', 'representation': '', 'algorithm': '', 'candidate': '', 'cutoff': 0}\n",
    "    \n",
    "    filename = filename.split(' - ')\n",
    "    filename[2] = filename[2].split(' (')\n",
    "    filename[2][1] = filename[2][1].replace(').csv','')\n",
    "    filename[2][1] = filename[2][1].split('@')\n",
    "    \n",
    "    # es. 'description - Doc2Vec - Centroid Vector (All Items@10).csv' dopo gli split e replace diventa:\n",
    "    # ['description', 'Doc2Vec', ['Centroid Vector', ['All Items', '10']]]\n",
    "    \n",
    "    file_info['fields'] = filename[0]\n",
    "    file_info['representation'] = filename[1]\n",
    "    file_info['algorithm'] = filename[2][0]\n",
    "    file_info['candidate'] = filename[2][1][0] # 'All Items'\n",
    "    file_info['cutoff'] = int(filename[2][1][1]) # 10\n",
    "    \n",
    "    return file_info\n",
    "\n",
    "def checkFilename(filename, run):\n",
    "    file_info = getFileInfo(filename)\n",
    "    \n",
    "    return(\n",
    "        file_info['fields'] == run['fields'] and \n",
    "        file_info['candidate'] == run['candidate'] and\n",
    "        file_info['cutoff'] == run['cutoff']\n",
    "    )\n",
    "\n",
    "def setPrefix(metric):\n",
    "    if(metric == 'Precision' or metric == 'Recall' or metric == 'F1' or metric == 'NDCG' or metric == 'MRR'):\n",
    "        return f'{metric}@'\n",
    "    elif(metric == 'Gini' or metric == 'CatalogCoverage' or metric == 'DeltaGap'):\n",
    "        return f'{metric} - Top '\n",
    "\n",
    "def setSuffix(metric, cutoff):\n",
    "    if(metric == 'Precision@' or metric == 'Recall@' or metric == 'F1@'):\n",
    "        return f'{metric}{cutoff} - macro'\n",
    "    elif(metric == 'NDCG@' or metric == 'MRR@' or metric == 'Gini - Top ' or metric == 'CatalogCoverage - Top '):\n",
    "        return f'{metric}{cutoff}'\n",
    "\n",
    "def getMetricValue(current_dir, filename, metric_string, candidate):\n",
    "    dataframe = pd.read_csv(current_dir + filename)\n",
    "    \n",
    "    file_info = getFileInfo(filename)\n",
    "    ID = f'{file_info[\"algorithm\"]} + {file_info[\"representation\"]}'\n",
    "\n",
    "    return ID, dataframe[metric_string][1]\n",
    "\n",
    "def shortenColumn(run):\n",
    "    if (run[\"candidate\"] == 'Test Ratings'):\n",
    "        candidate = '(TR)'\n",
    "    elif (run[\"candidate\"] == 'All Items'):\n",
    "        candidate = '(AI)'\n",
    "        \n",
    "    return f'{run[\"metric\"]}@{run[\"cutoff\"]} {candidate}'\n",
    "\n",
    "candidate_items = ['Test Ratings', 'All Items']\n",
    "\n",
    "representations_list =  [\n",
    "            'SK-TFIDF',\n",
    "            'Word2Vec', 'Doc2Vec',\n",
    "            'GensimLDA','GensimRandomIndexing', 'GensimFastText', 'GensimLSA',\n",
    "            'Word2Doc-GloVe','Sentence2Doc-Sbert']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e7d4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/Repository/RecSys-Algorithms-Evaluation/'\n",
    "dir = f'{path}/Eval Results - 1M/SYS/'\n",
    "result_path = f'{path}/Metrics/'\n",
    "\n",
    "def metricToTable(metric, field):\n",
    "    run = {'fields' : field, 'metric': metric, 'candidate': '', 'cutoff': []}\n",
    "    data = {'ID':[]}\n",
    "    frames = []\n",
    "    metric_string = ''\n",
    "    \n",
    "    # itera tra le rappresentazioni per la combinazione metrica-campo in considerazione\n",
    "    for representation in representations_list:\n",
    "        # itera tra le directories in base alla rappresentazione\n",
    "        current_dir = f'{dir}{representation}/'\n",
    "        # itera tra i candidate items\n",
    "        for candidate in candidate_items:\n",
    "            run['candidate'] = candidate\n",
    "            # sceglie il cutoff in base al candidate item considerato\n",
    "            if(run['candidate'] == 'Test Ratings'):\n",
    "                cutoffs = [5,10]\n",
    "            else:\n",
    "                cutoffs = [10,20]\n",
    "            # itera sui due cutoffs scelti\n",
    "            for cutoff in cutoffs:\n",
    "                run['cutoff'] = cutoff\n",
    "                # inserisce cutoff e suffisso all'ID della metrica\n",
    "                metric_string = setPrefix(run['metric'])\n",
    "                metric_string = setSuffix(metric_string, run['cutoff'])\n",
    "                # itera tra tutti i file di una data rappresentazione\n",
    "                for filename in os.listdir(current_dir):\n",
    "                    # controlla se il nome del file soddisfa il campo in considerazione, candidate e cutoff\n",
    "                    if(checkFilename(filename, run)):\n",
    "                    # prende valore e combinazione algoritmo/rappresentazione\n",
    "                        id, val = getMetricValue(current_dir, filename, metric_string, run['candidate'])\n",
    "                        column_name = shortenColumn(run)\n",
    "                        \n",
    "                        data['ID'].append(id)\n",
    "                        \n",
    "                        if column_name in data:\n",
    "                            data[column_name].append(round(val,4))\n",
    "                        else:\n",
    "                            data[column_name] = []\n",
    "                            data[column_name].append(round(val,4))\n",
    "                \n",
    "                # crea un dataframe dal dizionario\n",
    "                df = pd.DataFrame.from_dict(data)\n",
    "                # aggiunge il dataframe alla lista dei dataframe da concatenare\n",
    "                frames.append(df)\n",
    "                # svuota il dizionario\n",
    "                data = {'ID':[]}\n",
    "                \n",
    "                \n",
    "    metric_df = pd.concat(frames)\n",
    "\n",
    "    metric_df = metric_df.groupby('ID').agg({\n",
    "        'ID': 'first',\n",
    "        f'{metric}@5 (TR)': sum,  \n",
    "        f'{metric}@10 (TR)': sum\n",
    "        #f'{metric}@10 (AI)': sum,  \n",
    "        #f'{metric}@20 (AI)': sum\n",
    "    })\n",
    "    \n",
    "    metric_df.rename(columns={'ID': f'ID (Field: {field})'}, inplace = True)\n",
    "    \n",
    "    df_styled = metric_df.style.background_gradient().set_properties(**{'text-align': 'left'})\n",
    "    \n",
    "    if metric == 'CatalogCoverage':\n",
    "        rounding = 1\n",
    "    else:\n",
    "        rounding = 3\n",
    "        \n",
    "    df_styled.set_precision(rounding)\n",
    "    df_styled.hide_index()\n",
    "\n",
    "    csv_output = f'{result_path}/CSVs/[1M] {run[\"metric\"]} - {run[\"fields\"]}.csv'\n",
    "    png_output = f'{result_path}/PNGs/{metric}/[1M] {run[\"metric\"]} - {run[\"fields\"]}.png'\n",
    "    \n",
    "    metric_df.to_csv(csv_output, index = False)\n",
    "    dfi.export(df_styled, png_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38384d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkFilename(filename, field, metric):\n",
    "    filename = filename.replace('[1M] ', '')\n",
    "    filename = filename.replace('.csv', '')\n",
    "    filename = filename.split(\" - \")\n",
    "    \n",
    "    return(filename[0] == metric and filename[1] == field)\n",
    "\n",
    "def pair_metrics(field, first_metric, second_metric):\n",
    "    path = 'D:/Repository/RecSys-Algorithms-Evaluation/'\n",
    "    result_path = f'{path}Metrics/CSVs/'\n",
    "    output_path = f'{path}Metrics/PNGs/'\n",
    "    \n",
    "    for filename in os.listdir(result_path):\n",
    "        if(checkFilename(filename, field, first_metric)):\n",
    "            df1 = pd.read_csv(result_path + filename)\n",
    "    \n",
    "    for filename in os.listdir(result_path):\n",
    "        if(checkFilename(filename, field, second_metric)):\n",
    "            df2 = pd.read_csv(result_path + filename)\n",
    "    \n",
    "    res = pd.concat([df1,df2])\n",
    "    \n",
    "    res = res.groupby(f'ID (Field: {field})').agg({\n",
    "        f'ID (Field: {field})': 'first',\n",
    "        f'{first_metric}@5 (TR)': sum,  \n",
    "        f'{first_metric}@10 (TR)': sum,\n",
    "        f'{second_metric}@5 (TR)': sum,  \n",
    "        f'{second_metric}@10 (TR)': sum,\n",
    "    })\n",
    "    \n",
    "    if metric == 'CatalogCoverage':\n",
    "        rounding = 1\n",
    "    else:\n",
    "        rounding = 3\n",
    "    \n",
    "    df_styled = res.style.background_gradient().set_properties(**{'text-align': 'left'})\n",
    "    df_styled.set_precision(rounding)\n",
    "    df_styled.hide_index()\n",
    "    \n",
    "    png_output = f'{output_path}{first_metric} - {second_metric}/[1M] {first_metric} + {second_metric} - {field}.png'\n",
    "    dfi.export(df_styled, png_output)\n",
    "\n",
    "pair_metrics('description', 'Precision', 'Recall')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d9a45459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDeltaValue(current_dir, filename, metric_string, candidate):\n",
    "    dataframe = pd.read_csv(current_dir + filename)\n",
    "    \n",
    "    file_info = getFileInfo(filename)\n",
    "    ID = f'{file_info[\"algorithm\"]} + {file_info[\"representation\"]}'\n",
    "\n",
    "    return ID, dataframe[metric_string][1]\n",
    "\n",
    "def deltaToTable(metric, field, cf):\n",
    "    run = {'fields' : field, 'metric': metric, 'candidate': '', 'cutoff': []}\n",
    "    data = {'ID':[]}\n",
    "    suffixs = [' | Blockbuster', ' | Niche', ' | Diverse']\n",
    "    frames = []\n",
    "    delta_frames = []\n",
    "    metric_string = ''\n",
    "    cutoffs = []\n",
    "    cutoffs.append(cf)\n",
    "    \n",
    "    # itera tra le rappresentazioni per la combinazione metrica-campo in considerazione\n",
    "   \n",
    "    for representation in representations_list:\n",
    "        # itera tra le directories in base alla rappresentazione\n",
    "        current_dir = f'{dir}{representation}/'\n",
    "        # itera tra i candidate items\n",
    "        for candidate in candidate_items:\n",
    "            run['candidate'] = candidate\n",
    "            # sceglie il cutoff in base al candidate item considerato\n",
    "            if(run['candidate'] == 'Test Ratings'):\n",
    "                cutoffs.append(cf)\n",
    "            #else:\n",
    "                #cutoffs = [10,20]\n",
    "            # itera sui due cutoffs scelti\n",
    "            for cutoff in cutoffs:\n",
    "                run['cutoff'] = cutoff\n",
    "                data[f'DeltaGAP@{cf} | Blockbuster'] = []\n",
    "                data[f'DeltaGAP@{cf} | Niche'] = []\n",
    "                data[f'DeltaGAP@{cf} | Diverse'] = []\n",
    "                # itera tra tutti i file di una data rappresentazione\n",
    "                for filename in os.listdir(current_dir):\n",
    "                    # controlla se il nome del file soddisfa il campo in considerazione, candidate e cutoff\n",
    "                    if(checkFilename(filename, run)):\n",
    "                        # prende valore e combinazione algoritmo/rappresentazione\n",
    "                        for suffix in suffixs:\n",
    "                            metric_string = f'DeltaGap - Top {cutoff}{suffix}'\n",
    "                            id, val = getMetricValue(current_dir, filename, metric_string, run['candidate'])\n",
    "                            column_name = f'DeltaGAP@{cutoff}{suffix}'\n",
    "                            \n",
    "                            data['ID'].append(id)\n",
    "                            data[column_name].append(round(val,4))\n",
    "        \n",
    "                            keys = data.keys()\n",
    "                            for key in keys:\n",
    "                                if(key != column_name and key!='ID'):\n",
    "                                    data[key].append(0)\n",
    "\n",
    "                # crea un dataframe dal dizionario\n",
    "                df = pd.DataFrame.from_dict(data)\n",
    "                # aggiunge il dataframe alla lista dei dataframe da concatenare\n",
    "                frames.append(df)\n",
    "                # svuota il dizionario\n",
    "                data = {'ID':[]}\n",
    "\n",
    "    metric_df = pd.concat(frames)\n",
    "    \n",
    "    # modificare questa (e aggiungere 0 nei campi non interessati in fase di \n",
    "    # retrieve delle tuple) se si vogliono entrambi i cutoff in tabella\n",
    "    metric_df = metric_df.groupby('ID').agg({\n",
    "        'ID': 'first',\n",
    "        f'DeltaGAP@{cutoff} | Blockbuster': sum,\n",
    "        f'DeltaGAP@{cutoff} | Niche': sum,  \n",
    "        f'DeltaGAP@{cutoff} | Diverse': sum,   \n",
    "    })\n",
    "    \n",
    "    metric_df.rename(columns={'ID': f'ID (Field: {field})'}, inplace = True)\n",
    "    \n",
    "    \n",
    "    #df_styled = metric_df.style.background_gradient(axis=0, gmap=(metric_df[f'DeltaGAP@{cutoff} | Blockbuster']), cmap='YlOrRd')\n",
    "    df_styled = metric_df.style.background_gradient().set_properties(**{'text-align': 'left'})\n",
    "\n",
    "    df_styled.set_precision(3)\n",
    "    df_styled.hide_index()\n",
    "\n",
    "    csv_output = f'{result_path}/CSVs/[1M] {run[\"metric\"]} - {run[\"fields\"]}.csv'\n",
    "    png_output = f'{result_path}/PNGs/DeltaGAP/[1M] {run[\"metric\"]}@{cf} - {run[\"fields\"]}.png'\n",
    "\n",
    "    #metric_df.to_csv(csv_output, index = False)\n",
    "    dfi.export(df_styled, png_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3378209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "metrics = ['Precision', 'Recall', 'MRR', 'NDCG', 'Gini', 'CatalogCoverage', 'F1']\n",
    "fields = [\n",
    "    'description',\n",
    "    'genres',\n",
    "    'tags',\n",
    "    'reviews',\n",
    "    'description,genres,tags',\n",
    "    'description,genres,reviews',\n",
    "    'description,tags,reviews',\n",
    "    'genres,tags,reviews',\n",
    "    'description,genres,tags,reviews'\n",
    "]\n",
    "\n",
    "for field in fields:\n",
    "    for metric in metrics:\n",
    "        metricToTable(metric, field)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fedaba1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for field in fields:\n",
    "    for cutoff in [5,10]:\n",
    "        deltaToTable('DeltaGap', field, cutoff)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93736d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

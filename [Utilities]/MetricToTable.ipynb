{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f00e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2107fdcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3dc89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bbc381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bdd442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e7d4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import dataframe_image as dfi\n",
    "\n",
    "path = 'D:/Repository/RecSys-Algorithms-Evaluation/'\n",
    "dir = f'{path}/Eval Results - 1M/SYS/'\n",
    "result_path = f'{path}/Metrics/'\n",
    "\n",
    "def getFileInfo(filename):\n",
    "    file_info = {'fields' : '', 'representation': '', 'algorithm': '', 'candidate': '', 'cutoff': 0}\n",
    "    \n",
    "    filename = filename.split(' - ')\n",
    "    filename[2] = filename[2].split(' (')\n",
    "    filename[2][1] = filename[2][1].replace(').csv','')\n",
    "    filename[2][1] = filename[2][1].split('@')\n",
    "    \n",
    "    # es. 'description - Doc2Vec - Centroid Vector (All Items@10).csv' dopo gli split e replace diventa:\n",
    "    # ['description', 'Doc2Vec', ['Centroid Vector', ['All Items', '10']]]\n",
    "    \n",
    "    file_info['fields'] = filename[0]\n",
    "    file_info['representation'] = filename[1]\n",
    "    file_info['algorithm'] = filename[2][0]\n",
    "    file_info['candidate'] = filename[2][1][0] # 'All Items'\n",
    "    file_info['cutoff'] = int(filename[2][1][1]) # 10\n",
    "    \n",
    "    return file_info\n",
    "\n",
    "def checkFilename(filename, run):\n",
    "    file_info = getFileInfo(filename)\n",
    "    \n",
    "    return(\n",
    "        file_info['fields'] == run['fields'] and \n",
    "        file_info['candidate'] == run['candidate'] and\n",
    "        file_info['cutoff'] == run['cutoff']\n",
    "    )\n",
    "\n",
    "def setPrefix(metric):\n",
    "    if(metric == 'Precision' or metric == 'Recall' or metric == 'F1' or metric == 'NDCG' or metric == 'MRR'):\n",
    "        return f'{metric}@'\n",
    "    elif(metric == 'Gini' or metric == 'CatalogCoverage' or metric == 'DeltaGap'):\n",
    "        return f'{metric} - Top '\n",
    "\n",
    "def setSuffix(metric, cutoff):\n",
    "    if(metric == 'Precision@' or metric == 'Recall@' or metric == 'F1@'):\n",
    "        return f'{metric}{cutoff} - macro'\n",
    "    elif(metric == 'NDCG@' or metric == 'MRR@' or metric == 'Gini - Top ' or metric == 'CatalogCoverage - Top '):\n",
    "        return f'{metric}{cutoff}'\n",
    "\n",
    "def getMetricValue(current_dir, filename, metric_string, candidate):\n",
    "    dataframe = pd.read_csv(current_dir + filename)\n",
    "    \n",
    "    file_info = getFileInfo(filename)\n",
    "    ID = f'{file_info[\"algorithm\"]} + {file_info[\"representation\"]}'\n",
    "\n",
    "    return ID, dataframe[metric_string][1]\n",
    "\n",
    "def shortenColumn(run):\n",
    "    if(run['metric'] == 'Catalog Coverage'):\n",
    "        metric = 'Coverage'\n",
    "    else:\n",
    "        metric = run['metric']\n",
    "\n",
    "    if (run[\"candidate\"] == 'Test Ratings'):\n",
    "        candidate = '(TR)'\n",
    "    elif (run[\"candidate\"] == 'All Items'):\n",
    "        candidate = '(AI)'\n",
    "    return f'{run[\"metric\"]}@{run[\"cutoff\"]} {candidate}'\n",
    "\n",
    "candidate_items = ['Test Ratings', 'All Items']\n",
    "\n",
    "representations_list =  [\n",
    "            'SK-TFIDF',\n",
    "            'Word2Vec', 'Doc2Vec',\n",
    "            'GensimLDA','GensimRandomIndexing', 'GensimFastText', 'GensimLSA',\n",
    "            'Word2Doc-GloVe','Sentence2Doc-Sbert']\n",
    "\n",
    "def metricToTable(metric, field):\n",
    "    run = {'fields' : field, 'metric': metric, 'candidate': '', 'cutoff': []}\n",
    "    data = {'ID':[]}\n",
    "    frames = []\n",
    "    metric_string = ''\n",
    "    \n",
    "    # itera tra le rappresentazioni per la combinazione metrica-campo in considerazione\n",
    "    for representation in representations_list:\n",
    "        # itera tra le directories in base alla rappresentazione\n",
    "        current_dir = f'{dir}{representation}/'\n",
    "        # itera tra i candidate items\n",
    "        for candidate in candidate_items:\n",
    "            run['candidate'] = candidate\n",
    "            # sceglie il cutoff in base al candidate item considerato\n",
    "            if(run['candidate'] == 'Test Ratings'):\n",
    "                cutoffs = [5,10]\n",
    "            else:\n",
    "                cutoffs = [10,20]\n",
    "            # itera sui due cutoffs scelti\n",
    "            for cutoff in cutoffs:\n",
    "                run['cutoff'] = cutoff\n",
    "                # inserisce cutoff e suffisso all'ID della metrica\n",
    "                metric_string = setPrefix(run['metric'])\n",
    "                metric_string = setSuffix(metric_string, run['cutoff'])\n",
    "                # itera tra tutti i file di una data rappresentazione\n",
    "                for filename in os.listdir(current_dir):\n",
    "                    # controlla se il nome del file soddisfa il campo in considerazione, candidate e cutoff\n",
    "                    if(checkFilename(filename, run)):\n",
    "                    # prende valore e combinazione algoritmo/rappresentazione\n",
    "                        id, val = getMetricValue(current_dir, filename, metric_string, run['candidate'])\n",
    "                        column_name = shortenColumn(run)\n",
    "                        \n",
    "                        data['ID'].append(id)\n",
    "                        \n",
    "                        if column_name in data:\n",
    "                            data[column_name].append(round(val,4))\n",
    "                        else:\n",
    "                            data[column_name] = []\n",
    "                            data[column_name].append(round(val,4))\n",
    "                \n",
    "                # crea un dataframe dal dizionario\n",
    "                df = pd.DataFrame.from_dict(data)\n",
    "                # aggiunge il dataframe alla lista dei dataframe da concatenare\n",
    "                frames.append(df)\n",
    "                # svuota il dizionario\n",
    "                data = {'ID':[]}\n",
    "                \n",
    "                \n",
    "    metric_df = pd.concat(frames)\n",
    "\n",
    "    metric_df = metric_df.groupby('ID').agg({\n",
    "        'ID': 'first',\n",
    "        f'{metric}@5 (TR)': sum,  \n",
    "        f'{metric}@10 (TR)': sum,\n",
    "        f'{metric}@10 (AI)': sum,  \n",
    "        f'{metric}@20 (AI)': sum\n",
    "    })\n",
    "    \n",
    "    df_styled = metric_df.style.background_gradient()\n",
    "    df_styled.set_precision(3)\n",
    "    df_styled.hide_index()\n",
    "    \n",
    "    output_name = f'{result_path}[1M] {run[\"metric\"]} - {run[\"fields\"]}.png'\n",
    "    dfi.export(df_styled, output_name)\n",
    "\n",
    "    \n",
    "metrics = ['Precision', 'Recall', 'MRR', 'NDCG', 'Gini', 'CatalogCoverage', 'F1']\n",
    "\n",
    "for metric in metrics:\n",
    "    metricToTable(metric, 'description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3378209d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
